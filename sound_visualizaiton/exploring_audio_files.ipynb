{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://wiki.python.org/moin/Audio/\n",
    "\n",
    "https://wiki.python.org/moin/PythonInMusic\n",
    "\n",
    "https://cloud.google.com/speech-to-text/docs/best-practices\n",
    "\n",
    "https://www.swharden.com/wp/2016-07-19-realtime-audio-visualization-in-python/<BR>\n",
    "https://www.swharden.com/wp/2016-07-31-real-time-audio-monitor-with-pyqt/\n",
    "\n",
    "https://github.com/librosa/librosa<BR>\n",
    "http://librosa.github.io/librosa/\n",
    "    \n",
    "http://audiotools.sourceforge.net/\n",
    "    \n",
    "https://cloud.google.com/speech-to-text/docs/best-practices "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audioread\n",
    "\n",
    "https://pypi.org/project/audioread/<BR>\n",
    "http://audiotools.sourceforge.net/programming/audiotools.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install audioread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import audioread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with audioread.audio_open('Voice 002.m4a') as f:\n",
    "    print(f.channels, f.samplerate, f.duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with audioread.audio_open('Voice 003.m4a') as f:\n",
    "    print(f.channels, f.samplerate, f.duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "subprocess.Popen(['ffmpeg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pydub\n",
    "\n",
    "https://github.com/jiaaro/pydub<BR>\n",
    "https://pydub.com/\n",
    "    \n",
    "https://stackoverflow.com/questions/37725416/pydub-combine-split-on-silence-with-minimum-length-file-size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "# 47MB m4a file is too big for 8GB of memory\n",
    "#audio = AudioSegment.from_file('Voice 002.m4a')\n",
    "audio = AudioSegment.from_file('Dec 29 11am Ben and Tracie driving.m4a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "channel_count= 1\n",
      "sample_width= 4\n",
      "duration_in_sec= 1322.585\n",
      "frame_rate= 44100\n"
     ]
    }
   ],
   "source": [
    "channel_count = audio.channels    #Get channels\n",
    "print(\"channel_count=\", channel_count)\n",
    "sample_width = audio.sample_width #Get sample width\n",
    "print(\"sample_width=\", sample_width )\n",
    "duration_in_sec = len(audio) / 1000#Length of audio in sec\n",
    "print(\"duration_in_sec=\", duration_in_sec )\n",
    "sample_rate = audio.frame_rate\n",
    "print(\"frame_rate=\", sample_rate)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# https://stackoverflow.com/questions/43204441/how-to-split-the-audio-file-in-python\n",
    "from pydub import AudioSegment\n",
    "sound = AudioSegment.from_file('Voice 003.m4a')\n",
    "\n",
    "halfway_point = len(sound) // 2\n",
    "first_half = sound[:halfway_point]\n",
    "\n",
    "# create a new file \"first_half.mp3\":\n",
    "first_half.export(\"first_half.mp3\", format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function split_on_silence in module pydub.silence:\n",
      "\n",
      "split_on_silence(audio_segment, min_silence_len=1000, silence_thresh=-16, keep_silence=100, seek_step=1)\n",
      "    audio_segment - original pydub.AudioSegment() object\n",
      "    \n",
      "    min_silence_len - (in ms) minimum length of a silence to be used for\n",
      "        a split. default: 1000ms\n",
      "    \n",
      "    silence_thresh - (in dBFS) anything quieter than this will be\n",
      "        considered silence. default: -16dBFS\n",
      "    \n",
      "    keep_silence - (in ms) amount of silence to leave at the beginning\n",
      "        and end of the chunks. Keeps the sound from sounding like it is\n",
      "        abruptly cut off. (default: 100ms)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# https://github.com/jiaaro/pydub/blob/master/pydub/silence.py\n",
    "from pydub.silence import split_on_silence\n",
    "help(split_on_silence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = split_on_silence(\n",
    "    audio,\n",
    "\n",
    "    # split on silences longer than 1000ms (1 sec)\n",
    "    min_silence_len=1000,\n",
    "\n",
    "    # anything under -16 dBFS is considered silence\n",
    "    silence_thresh=-16, \n",
    "\n",
    "    # keep 200 ms of leading/trailing silence\n",
    "    keep_silence=200\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, chunk in enumerate(chunks):\n",
    "    chunk.export(\"chunk{0}.wav\".format(i), format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metadata using mutagen\n",
    "\n",
    "https://mutagen.readthedocs.io/en/latest/api/mp4.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install mutagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mutagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutagen.File('Voice 002.m4a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Voice 002.m4a') as f:\n",
    "    mutagen.mp4.MP4Info(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metadata using tinytag\n",
    "\n",
    "https://github.com/devsnd/tinytag<BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tinytag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tinytag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tinytag import TinyTag\n",
    "tag = TinyTag.get('Voice 002.m4a')\n",
    "print('This track is by %s.' % tag.artist)\n",
    "print('It is %f seconds long.' % tag.duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('album:',tag.album)         # album as string\n",
    "print('album artist:',tag.albumartist)   # album artist as string\n",
    "print('artist:',tag.artist)        # artist name as string\n",
    "print('audio offset:',tag.audio_offset)  # number of bytes before audio data begins\n",
    "print('bitrate:',tag.bitrate)       # bitrate in kBits/s\n",
    "print('comment:',tag.comment)       # file comment as string\n",
    "print('disc:',tag.disc)          # disc number\n",
    "print('total:',tag.disc_total)    # the total number of discs\n",
    "print('duration:',tag.duration)      # duration of the song in seconds\n",
    "print('filesize:',tag.filesize)      # file size in bytes\n",
    "print('genre:',tag.genre)         # genre as string\n",
    "print('sample rate:',tag.samplerate)    # samples per second\n",
    "print('title:',tag.title)         # title of the song\n",
    "print('track:',tag.track)         # track number as string\n",
    "print('track total:',tag.track_total)   # total number of tracks as string\n",
    "print('year:',tag.year)          # year or data as string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Speaker diarisation\n",
    "https://en.wikipedia.org/wiki/Speaker_diarisation\n",
    "\n",
    "https://ai.googleblog.com/2018/11/accurate-online-speaker-diarization.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pyAudioAnalysis\n",
    "\n",
    "https://github.com/tyiannak/pyAudioAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pyAudioAnalysis\n",
    "!pip install python-magic\n",
    "!pip install eyed3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyAudioAnalysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tyiannak/pyAudioAnalysis/wiki/5.-Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyAudioAnalysis import audioBasicIO as aIO\n",
    "from pyAudioAnalysis import audioSegmentation as aS\n",
    "[Fs, x] = aIO.readAudioFile('Voice 002.m4a')\n",
    "segments = aS.silenceRemoval(x, Fs, 0.020, 0.020, smoothWindow = 1.0, Weight = 0.3, plot = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sound visualization\n",
    "\n",
    "http://www.frank-zalkow.de/en/code-snippets/create-audio-spectrograms-with-python.html?i=1\n",
    "\n",
    "https://pythontic.com/visualization/signals/spectrogram\n",
    "\n",
    "https://stackoverflow.com/questions/44787437/how-to-convert-a-wav-file-to-a-spectrogram-in-python3\n",
    "\n",
    "https://graphthinking.blogspot.com/2017/11/visualizing-audio-data-amplitude-volume.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# works, but output file is too big:\n",
    "# input m4a is 47MB, output wav is 256MB\n",
    "\n",
    "# convert m4a to wav\n",
    "!rm *.wav\n",
    "#!ffmpeg -i Voice\\ 002.m4a voice_002.wav\n",
    "\n",
    "#!ffmpeg -i Dec 29 11am Ben and Tracie driving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io.wavfile\n",
    "# scipy.io.wavfile.read can read only PCM and floating point formats (WAVE_FORMAT_PCM and WAVE_FORMAT_IEEE_FLOAT)\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.wavfile.read.html\n",
    "FSample, samples = scipy.io.wavfile.read('voice_002.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(FSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(FSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(samples[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 3.4.4-0ubuntu0.18.04.1 Copyright (c) 2000-2018 the FFmpeg developers\n",
      "  built with gcc 7 (Ubuntu 7.3.0-16ubuntu3)\n",
      "  configuration: --prefix=/usr --extra-version=0ubuntu0.18.04.1 --toolchain=hardened --libdir=/usr/lib/x86_64-linux-gnu --incdir=/usr/include/x86_64-linux-gnu --enable-gpl --disable-stripping --enable-avresample --enable-avisynth --enable-gnutls --enable-ladspa --enable-libass --enable-libbluray --enable-libbs2b --enable-libcaca --enable-libcdio --enable-libflite --enable-libfontconfig --enable-libfreetype --enable-libfribidi --enable-libgme --enable-libgsm --enable-libmp3lame --enable-libmysofa --enable-libopenjpeg --enable-libopenmpt --enable-libopus --enable-libpulse --enable-librubberband --enable-librsvg --enable-libshine --enable-libsnappy --enable-libsoxr --enable-libspeex --enable-libssh --enable-libtheora --enable-libtwolame --enable-libvorbis --enable-libvpx --enable-libwavpack --enable-libwebp --enable-libx265 --enable-libxml2 --enable-libxvid --enable-libzmq --enable-libzvbi --enable-omx --enable-openal --enable-opengl --enable-sdl2 --enable-libdc1394 --enable-libdrm --enable-libiec61883 --enable-chromaprint --enable-frei0r --enable-libopencv --enable-libx264 --enable-shared\n",
      "  libavutil      55. 78.100 / 55. 78.100\n",
      "  libavcodec     57.107.100 / 57.107.100\n",
      "  libavformat    57. 83.100 / 57. 83.100\n",
      "  libavdevice    57. 10.100 / 57. 10.100\n",
      "  libavfilter     6.107.100 /  6.107.100\n",
      "  libavresample   3.  7.  0 /  3.  7.  0\n",
      "  libswscale      4.  8.100 /  4.  8.100\n",
      "  libswresample   2.  9.100 /  2.  9.100\n",
      "  libpostproc    54.  7.100 / 54.  7.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'Voice 002.m4a':\n",
      "  Metadata:\n",
      "    major_brand     : 3gp4\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isom3gp4\n",
      "    creation_time   : 2018-12-29T18:22:36.000000Z\n",
      "    com.android.version: 6.0.1\n",
      "  Duration: 00:48:29.53, start: 0.000000, bitrate: 129 kb/s\n",
      "    Stream #0:0(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2018-12-29T18:22:36.000000Z\n",
      "      handler_name    : SoundHandle\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out000.wav' for writing\n",
      "Output #0, segment, to 'out%03d.wav':\n",
      "  Metadata:\n",
      "    major_brand     : 3gp4\n",
      "    minor_version   : 0\n",
      "    compatible_brands: isom3gp4\n",
      "    com.android.version: 6.0.1\n",
      "    encoder         : Lavf57.83.100\n",
      "    Stream #0:0(eng): Audio: aac (LC) (mp4a / 0x6134706D), 44100 Hz, mono, fltp, 128 kb/s (default)\n",
      "    Metadata:\n",
      "      creation_time   : 2018-12-29T18:22:36.000000Z\n",
      "      handler_name    : SoundHandle\n",
      "Stream mapping:\n",
      "  Stream #0:0 -> #0:0 (copy)\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out001.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out002.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out003.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out004.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out005.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out006.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out007.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out008.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out009.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out010.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out011.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out012.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out013.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out014.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out015.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out016.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out017.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out018.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out019.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out020.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out021.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out022.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out023.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out024.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out025.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out026.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out027.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out028.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out029.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out030.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out031.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out032.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out033.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out034.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out035.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out036.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out037.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out038.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out039.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out040.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out041.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out042.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out043.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out044.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out045.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out046.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out047.wav' for writing\n",
      "\u001b[1;35m[segment @ 0x564e9933ffc0] \u001b[0mOpening 'out048.wav' for writing\n",
      "size=N/A time=00:48:29.50 bitrate=N/A speed= 415x    \n",
      "video:0kB audio:45461kB subtitle:0kB other streams:0kB global headers:0kB muxing overhead: unknown\n"
     ]
    }
   ],
   "source": [
    "# this works for splitting on time, but the .wav can't be read by scipy\n",
    "\n",
    "# convert m4a to wav\n",
    "# split into N second chunks\n",
    "# https://unix.stackexchange.com/questions/280767/how-do-i-split-an-audio-file-into-multiple\n",
    "\n",
    "!rm *.wav\n",
    "!ffmpeg -i Voice\\ 002.m4a -f segment -segment_time 60 -c copy out%03d.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSample, samples = scipy.io.wavfile.read('out002.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what formats are available?\n",
    "# https://trac.ffmpeg.org/wiki/audio%20types\n",
    "!ffmpeg -formats | grep -i pcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.wav\n",
    "!ffmpeg -i Voice\\ 002.m4a -f s8 -c copy voice_002.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i voice_002.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSample, samples = scipy.io.wavfile.read('voice_002.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify format for output when splitting; output .wav can't be read by scipy\n",
    "!rm *.wav\n",
    "!ffmpeg -i Voice\\ 002.m4a  -f s16le -ar 16000 -ac 2 voice_002.wav\n",
    "\n",
    "#-f s16le = signed 16-bit little endian samples\n",
    "#-ac 2 = 2 channels (stereo)\n",
    "#-ar 16000 = sample rate 16000Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSample, samples = scipy.io.wavfile.read('voice_002.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.wav\n",
    "!ffmpeg -i Voice\\ 002.m4a -f s16le -acodec pcm_s16le voice_002.wav\n",
    "\n",
    "#-f s16le = signed 16-bit little endian samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i voice_002.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSample, samples = scipy.io.wavfile.read('voice_002.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm *.wav\n",
    "!ffmpeg -y  -i Voice\\ 002.m4a  -acodec pcm_s16le -f s16le -ac 1 -ar 16000 voice_002.wav\n",
    "\n",
    "#-f s16le = signed 16-bit little endian samples\n",
    "#-ac 1 = 1 channels (stereo)\n",
    "#-ar 16000 = sample rate 16000Hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FSample, samples = scipy.io.wavfile.read('voice_002.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.io import wavfile\n",
    "\n",
    "def graph_spectrogram(wav_file):\n",
    "    rate, data = get_wav_info(wav_file)\n",
    "    nfft = 256  # Length of the windowing segments\n",
    "    fs = 256    # Sampling frequency\n",
    "    pxx, freqs, bins, im = plt.specgram(data, nfft,fs)\n",
    "    plt.axis('off')\n",
    "    plt.savefig('sp_xyz.png',\n",
    "                dpi=100, # Dots per inch\n",
    "                frameon='false',\n",
    "                aspect='normal',\n",
    "                bbox_inches='tight',\n",
    "                pad_inches=0) # Spectrogram saved as a .png \n",
    "    plt.show()\n",
    "\n",
    "def get_wav_info(wav_file):\n",
    "    rate, data = wavfile.read(wav_file)\n",
    "    return rate, data\n",
    "    \n",
    "graph_spectrogram('Voice 002.m4a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sox\n",
    "https://en.wikipedia.org/wiki/SoX\n",
    "\n",
    "https://github.com/rabitt/pysox<BR>\n",
    "https://pysox.readthedocs.io/en/latest/\n",
    "\n",
    "https://gist.github.com/jochemstoel/05a4ac5337b829b023feb73ef97a31ed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
